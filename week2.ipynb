{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEAk3Ts9FytP"
      },
      "source": [
        "# DIKU NLP Course 2020/2021: Group Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQVVe8FWy_pS"
      },
      "source": [
        "## Preparations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apAD9srW2kwH"
      },
      "source": [
        "#### Mount Google Drive (datasets are stored there):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP4L-yFeYURJ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-lmFXoGyvc9"
      },
      "source": [
        "#### Enable reproducability\n",
        "\n",
        "Taken from https://nbviewer.jupyter.org/github/copenlu/stat-nlp-book/blob/master/labs/lab_2.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p94XilAyvdT"
      },
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def enforce_reproducibility(seed=42):\n",
        "  # Sets seed manually for both CPU and CUDA\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "  # For atomic operations there is currently no simple way to enforce \n",
        "  # determinism, as the order of parallel operations is not known.\n",
        "  # CUDNN\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  \n",
        "  # System based\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "\n",
        "enforce_reproducibility()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtaVl79pzm54"
      },
      "source": [
        "#### Load relevant questions from dataset, also download nltk word tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7lUS_on3q1x"
      },
      "source": [
        "import json\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# we use nltk to tokenize multi-lingual sequences\n",
        "def tokenize_at_word_level(input):\n",
        "  return nltk.tokenize.word_tokenize(input)\n",
        "\n",
        "# define supported languages\n",
        "supported_languages = ['english', 'arabic', 'finnish', 'korean']\n",
        "\n",
        "binary_labels = ['YES', 'NO']\n",
        "\n",
        "# helper function to return all relevant properties\n",
        "def relevant_properties(question):\n",
        "  return {\n",
        "    \"question\": question['question_text'],\n",
        "    \"document\": question['document_plaintext'],\n",
        "    \"answer\": question['annotations'][0]['yes_no_answer'].upper()\n",
        "  }\n",
        "\n",
        "# helper function to import questions from given file\n",
        "def import_questions(file):\n",
        "  questions = {}\n",
        "\n",
        "  for lang in supported_languages:\n",
        "    questions[lang] = []\n",
        "\n",
        "  for line in file:\n",
        "    question = json.loads(line)\n",
        "    lang = question['language']\n",
        "\n",
        "    # add question if dict contains key for it and it has yes/no answer \n",
        "    if (lang in list(questions.keys()) and\n",
        "        relevant_properties(question)['answer'] in binary_labels\n",
        "      ):\n",
        "      questions[lang].append(question)\n",
        "\n",
        "  return questions\n",
        "\n",
        "# questions used for training our classifier(s)\n",
        "with open(\"/content/drive/My Drive/NLP 2020W/tydiqa-v1.0-train.jsonl\") as file:\n",
        "  train_questions = import_questions(file)\n",
        "\n",
        "# questions used to evaluate our classifier(s)\n",
        "with open(\"/content/drive/My Drive/NLP 2020W/tydiqa-v1.0-dev.jsonl\") as file:\n",
        "  dev_questions = import_questions(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoaFHXPJVE-5"
      },
      "source": [
        "## 2 Representation Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2id3l42gVUDV"
      },
      "source": [
        "#### (a) Vector representations\n",
        "\n",
        "In assignment 2 (a) we extend the classifier to use features based on the continous vector representation of words. For that we train a Word2Vec model on all the words in the training dataset. We then use the vector representations of the individual words as inputs to the classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWGXOMCXI43Y"
      },
      "source": [
        "%%time\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "w2v_models = {}\n",
        "\n",
        "for lang in supported_languages:\n",
        "  print(\"Started training language: \" + lang)\n",
        "  question_list = [relevant_properties(q) for q in train_questions[lang]]\n",
        "\n",
        "  inputs = [tokenize_at_word_level(q[\"question\"] + \" \" + q['document']) for q in question_list]\n",
        "\n",
        "  # Create CBOW model\n",
        "  w2v_models[lang] = Word2Vec(inputs, min_count = 1, size = 4, window = 5)\n",
        "\n",
        "  # Create Skip Gram model\n",
        "  # w2v_models[lang] = Word2Vec(data, min_count = 1, size = 32, window = 5, sg = 1)\n",
        "  \n",
        "  print(\"Finished training language: \" + lang)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezSkIa8cDBN3"
      },
      "source": [
        "# get the features as vector representations\n",
        "def features_vr(text, lang):\n",
        "  features = defaultdict(float)\n",
        "  for w in tokenize_at_word_level(text):\n",
        "    try:\n",
        "      # take max value of word2vec as representation\n",
        "      vector_repr = max(w2v_models[lang][w])\n",
        "    except:\n",
        "      vector_repr = 0\n",
        "    features[vector_repr] += 1.0\n",
        "  return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZKg6DrRvdI1"
      },
      "source": [
        "# train logistic regression classifier using vector word representations\n",
        "def train_binary_log_reg_vec(lang):\n",
        "  train_data = [relevant_properties(q) for q in train_questions[lang]]\n",
        "  dev_data = [relevant_properties(q) for q in dev_questions[lang]]\n",
        "\n",
        "  vectorizer = DictVectorizer()\n",
        "\n",
        "  # we again use the concatenated question and document text as features\n",
        "  train_x = vectorizer.fit_transform([features_vr(q['question'] + \" \" + q['document'], lang) for q in train_data])\n",
        "  dev_x = vectorizer.transform([features_vr(q['question'] + \" \" + q['document'], lang) for q in dev_data])\n",
        "\n",
        "  label_encoder = LabelEncoder()\n",
        "  train_y = label_encoder.fit_transform([q['answer'] for q in train_data])\n",
        "  dev_y = label_encoder.fit_transform([q['answer'] for q in dev_data])\n",
        "\n",
        "  lr = LogisticRegression(C=1000, penalty=\"l1\", random_state=1, solver='liblinear')\n",
        "  lr.fit(train_x, train_y)\n",
        "\n",
        "  # inverse_transform transforms labels back to original encoding\n",
        "  return label_encoder.inverse_transform(lr.predict(dev_x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_E3YQmdyAEP"
      },
      "source": [
        "%%time\n",
        "for lang in supported_languages:\n",
        "  predictions = train_binary_log_reg_vec(lang)\n",
        "  actual = [relevant_properties(q)['answer'] for q in dev_questions[lang]]\n",
        "\n",
        "  print('Accuracy for language {}: {}'.format(lang, accuracy_score(actual, predictions)))\n",
        "  print('F1 score for language {}: {}'.format(lang, f1_score(actual, predictions, average='weighted')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E74m7Dzp2Tug"
      },
      "source": [
        "#### (b) Feature + vector representations\n",
        "\n",
        "In assignment 2 (b) we combine features and vector representations. Specifically we are going to use the vector representation of the entire question text instead of a list of the vector representations of the words in the text. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsXVxNY7FCd3"
      },
      "source": [
        "# represent the entire text as the maximum of its word vectors\n",
        "def features_vr_max(text, lang):\n",
        "  max = 0\n",
        "  for w in tokenize_at_word_level(text):\n",
        "    try:\n",
        "      # take max value of word2vec as representation\n",
        "      vector_repr = max(w2v_models[lang][w])\n",
        "      if (vector_repr > max):\n",
        "        max = vector_repr\n",
        "    except:\n",
        "      continue\n",
        "    \n",
        "  return {max: 1.0}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2Fw9vohEujT"
      },
      "source": [
        "# train logistic regression using features and vector representations\n",
        "def train_binary_log_reg_vec_max(lang):\n",
        "  train_data = [relevant_properties(q) for q in train_questions[lang]]\n",
        "  dev_data = [relevant_properties(q) for q in dev_questions[lang]]\n",
        "\n",
        "  vectorizer = DictVectorizer()\n",
        "\n",
        "  # note that the following two lines are different to 2(a)\n",
        "  train_x = vectorizer.fit_transform([features_vr_max(q['question'] + \" \" + q['document'], lang) for q in train_data])\n",
        "  dev_x = vectorizer.transform([features_vr_max(q['question'] + \" \" + q['document'], lang) for q in dev_data])\n",
        "\n",
        "  label_encoder = LabelEncoder()\n",
        "  train_y = label_encoder.fit_transform([q['answer'] for q in train_data])\n",
        "  dev_y = label_encoder.fit_transform([q['answer'] for q in dev_data])\n",
        "\n",
        "  lr = LogisticRegression(C=1000, penalty=\"l1\", random_state=1, solver='liblinear')\n",
        "  lr.fit(train_x, train_y)\n",
        "\n",
        "  # inverse_transform transforms labels back to original encoding\n",
        "  return label_encoder.inverse_transform(lr.predict(dev_x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jtRFqmqvUZa"
      },
      "source": [
        "%%time\n",
        "for lang in supported_languages:\n",
        "  predictions = train_binary_log_reg_vec_max(lang)\n",
        "  actual = [relevant_properties(q)['answer'] for q in dev_questions[lang]]\n",
        "\n",
        "  print('Accuracy for language {}: {}'.format(lang, accuracy_score(actual, predictions)))\n",
        "  print('F1 score for language {}: {}'.format(lang, f1_score(actual, predictions, average='weighted')))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}