{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEAk3Ts9FytP"
      },
      "source": [
        "# DIKU NLP Course 2020/2021: Group Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQVVe8FWy_pS"
      },
      "source": [
        "## Preparations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apAD9srW2kwH"
      },
      "source": [
        "#### Mount Google Drive (datasets are stored there):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP4L-yFeYURJ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-lmFXoGyvc9"
      },
      "source": [
        "#### Enable reproducability\n",
        "\n",
        "Taken from https://nbviewer.jupyter.org/github/copenlu/stat-nlp-book/blob/master/labs/lab_2.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p94XilAyvdT"
      },
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def enforce_reproducibility(seed=42):\n",
        "  # Sets seed manually for both CPU and CUDA\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "  # For atomic operations there is currently no simple way to enforce \n",
        "  # determinism, as the order of parallel operations is not known.\n",
        "  # CUDNN\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  \n",
        "  # System based\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "\n",
        "enforce_reproducibility()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtaVl79pzm54"
      },
      "source": [
        "#### Load relevant questions from dataset, also download nltk word tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7lUS_on3q1x"
      },
      "source": [
        "import json\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# we use nltk to tokenize multi-lingual sequences\n",
        "def tokenize_at_word_level(input):\n",
        "  return nltk.tokenize.word_tokenize(input)\n",
        "\n",
        "# define supported languages\n",
        "supported_languages = ['english', 'arabic', 'finnish', 'korean']\n",
        "\n",
        "binary_labels = ['YES', 'NO']\n",
        "\n",
        "# helper function to return all relevant properties\n",
        "def relevant_properties(question):\n",
        "  return {\n",
        "    \"question\": question['question_text'],\n",
        "    \"document\": question['document_plaintext'],\n",
        "    \"answer\": question['annotations'][0]['yes_no_answer'].upper()\n",
        "  }\n",
        "\n",
        "# helper function to import questions from given file\n",
        "def import_questions(file):\n",
        "  questions = {}\n",
        "\n",
        "  for lang in supported_languages:\n",
        "    questions[lang] = []\n",
        "\n",
        "  for line in file:\n",
        "    question = json.loads(line)\n",
        "    lang = question['language']\n",
        "\n",
        "    # add question if dict contains key for it and it has yes/no answer \n",
        "    if (lang in list(questions.keys()) and\n",
        "        relevant_properties(question)['answer'] in binary_labels\n",
        "      ):\n",
        "      questions[lang].append(question)\n",
        "\n",
        "  return questions\n",
        "\n",
        "# questions used for training our classifier(s)\n",
        "with open(\"/content/drive/My Drive/NLP 2020W/tydiqa-v1.0-train.jsonl\") as file:\n",
        "  train_questions = import_questions(file)\n",
        "\n",
        "# questions used to evaluate our classifier(s)\n",
        "with open(\"/content/drive/My Drive/NLP 2020W/tydiqa-v1.0-dev.jsonl\") as file:\n",
        "  dev_questions = import_questions(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEWPZkmUyUwa"
      },
      "source": [
        "## 1 Introduction to NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW7f_D--uQ2E"
      },
      "source": [
        "### 1.1 Preprocessing and dataset analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4mdb3fRzW71"
      },
      "source": [
        "#### (a) Preprocessing pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3bHLYCrzeF4"
      },
      "source": [
        "tokenize_at_word_level(\"This method may be used to tokenize sentences.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcT6SP5EkkZa"
      },
      "source": [
        "#### (b) Most common first tokens and common question words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYWtOsgSz1Hw"
      },
      "source": [
        "def first_tokens(questions):\n",
        "  first_tokens = {}\n",
        "\n",
        "  # store counter for each first token within dictionary\n",
        "  for lang in list(questions.keys()):\n",
        "    if lang not in first_tokens:\n",
        "      first_tokens[lang] = {}\n",
        "    for question in questions[lang]:\n",
        "      token = tokenize_at_word_level(question['question_text'])[0]\n",
        "      if token in first_tokens[lang]:\n",
        "        first_tokens[lang][token] += 1\n",
        "      else:\n",
        "        first_tokens[lang][token] = 1\n",
        "\n",
        "  return first_tokens\n",
        "\n",
        "first_tokens(train_questions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhPkQe9Yyhgr"
      },
      "source": [
        "### 1.2 Binary Question Classification\n",
        "\n",
        "We chose to go with a simple logistic regression model, the input being a concatenation of the question and document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n36NvqwF72oc"
      },
      "source": [
        "# return number of occurrences of words as feature dictionary\n",
        "def features(text, lang):\n",
        "  features = defaultdict(float)\n",
        "  for w in tokenize_at_word_level(text):\n",
        "    features[w] += 1.0\n",
        "  return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqz4kkYU7uEv"
      },
      "source": [
        "# train logistic regression classifier\n",
        "def train_binary_log_reg(lang):\n",
        "  train_data = [relevant_properties(q) for q in train_questions[lang]]\n",
        "  dev_data = [relevant_properties(q) for q in dev_questions[lang]]\n",
        "\n",
        "  vectorizer = DictVectorizer()\n",
        "\n",
        "  # we again use the concatenated question and document text as features\n",
        "  train_x = vectorizer.fit_transform([features(q['question'] + \" \" + q['document'], lang) for q in train_data])\n",
        "  dev_x = vectorizer.transform([features(q['question'] + \" \" + q['document'], lang) for q in dev_data])\n",
        "\n",
        "  label_encoder = LabelEncoder()\n",
        "  train_y = label_encoder.fit_transform([q['answer'] for q in train_data])\n",
        "  dev_y = label_encoder.fit_transform([q['answer'] for q in dev_data])\n",
        "\n",
        "  lr = LogisticRegression(C=1000, penalty=\"l1\", random_state=1, solver='liblinear')\n",
        "  lr.fit(train_x, train_y)\n",
        "\n",
        "  # inverse_transform transforms labels back to original encoding\n",
        "  return label_encoder.inverse_transform(lr.predict(dev_x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJEhzbn2r5ld"
      },
      "source": [
        "%%time\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# train binary classifier for all languages and evaluate the predictions\n",
        "for lang in supported_languages:\n",
        "  predictions = train_binary_log_reg(lang)\n",
        "  actual = [relevant_properties(q)['answer'] for q in dev_questions[lang]]\n",
        "\n",
        "  print('Accuracy for language {}: {}'.format(lang, accuracy_score(actual, predictions)))\n",
        "  print('F1 score for language {}: {}'.format(lang, f1_score(actual, predictions, average='weighted')))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}